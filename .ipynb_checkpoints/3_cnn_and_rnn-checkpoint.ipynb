{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUI02UFXY5lZ"
   },
   "source": [
    "# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ RNN. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞.\n",
    "\n",
    "–ü—Ä–∏–≤–µ—Ç! –í —ç—Ç–æ —Å–µ–º–∏–Ω–∞—Ä–µ –º—ã –ø–æ–∑–Ω–∞–∫–æ–º–∏–º—Å—è —Å –∑–∞–¥–∞—á–µ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞, –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ –ø–æ–∏—Å–∫–∞ —Ç–µ–º–∞—Ç–∏–∫–∏ –Ω–æ–≤–æ—Å—Ç–∏, –∞ —Ç–∞–∫–∂–µ —Å –¥–≤—É–º—è –∏–∑ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—Ç —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π ‚Äì¬†RNN –∏ GRU.\n",
    "\n",
    "–ù–∞–º –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –æ–¥–Ω–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –æ—Ç `HuggingFaceü§ó` –ø–æ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º `datasets`. –û–Ω–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –±–æ–ª—å—à–æ–µ —á–∏—Å–ª–æ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤ NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-07T15:04:25.467297Z",
     "start_time": "2022-09-07T15:03:51.812070Z"
    },
    "id": "4eSlBJXbpNhH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 365 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /Users/antonermak/opt/anaconda3/lib/python3.9/site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: packaging in /Users/antonermak/opt/anaconda3/lib/python3.9/site-packages (from datasets) (21.0)\n",
      "Collecting fsspec[http]>=2021.11.1\n",
      "  Downloading fsspec-2022.8.2-py3-none-any.whl (140 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 140 kB 23.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /Users/antonermak/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.20.3)\n",
      "Collecting pyarrow>=6.0.0\n",
      "  Downloading pyarrow-9.0.0-cp39-cp39-macosx_10_13_x86_64.whl (24.0 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 24.0 MB 6.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /Users/antonermak/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2.26.0)\n",
      "Collecting dill<0.3.6\n",
      "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95 kB 8.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.13-py39-none-any.whl (132 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 132 kB 5.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /Users/antonermak/opt/anaconda3/lib/python3.9/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: pandas in /Users/antonermak/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.4.2)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp39-cp39-macosx_10_9_x86_64.whl (34 kB)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120 kB 6.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /Users/antonermak/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/antonermak/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/antonermak/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/antonermak/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.6.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/antonermak/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/antonermak/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/antonermak/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (5.2.0)\n",
      "Requirement already satisfied: filelock in /Users/antonermak/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/antonermak/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/antonermak/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/antonermak/opt/anaconda3/lib/python3.9/site-packages (from packaging->datasets) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/antonermak/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/antonermak/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/antonermak/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.5.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/antonermak/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/antonermak/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/antonermak/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: fsspec, dill, xxhash, responses, pyarrow, multiprocess, huggingface-hub, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2021.8.1\n",
      "    Uninstalling fsspec-2021.8.1:\n",
      "      Successfully uninstalled fsspec-2021.8.1\n",
      "Successfully installed datasets-2.4.0 dill-0.3.5.1 fsspec-2022.8.2 huggingface-hub-0.9.1 multiprocess-0.70.13 pyarrow-9.0.0 responses-0.18.0 xxhash-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-07T15:04:42.748652Z",
     "start_time": "2022-09-07T15:04:25.470887Z"
    },
    "id": "gwNeXLCXr4ue"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import gensim.downloader as api\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-07T15:04:42.766434Z",
     "start_time": "2022-09-07T15:04:42.752149Z"
    },
    "id": "IBGF3mNQKAgN"
   },
   "outputs": [],
   "source": [
    "# –ó–∞ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º!\n",
    "SEED = 0xDEAD\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.random.manual_seed(SEED)\n",
    "torch.cuda.random.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YX-nNNuqZ9GN"
   },
   "source": [
    "–ó–∞–≥—Ä—É–∑–∏–º –¥–∞—Ç–∞—Å–µ—Ç –Ω–æ–≤–æ—Å—Ç–µ–π: `AgNews`. –í –Ω–µ–º —Ä–∞–∑–¥–µ–ª–µ–Ω—ã —Ç–µ–∫—Å—Ç—ã –Ω–∞ 4 —Ç–µ–º—ã: `World`, `Sports`, `Business`, `Sci/Tech`. –ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ –Ω–∞ –ø—Ä–∏–º–µ—Ä—ã —Ç–µ–∫—Å—Ç–æ–≤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-07T15:05:11.518822Z",
     "start_time": "2022-09-07T15:04:42.772130Z"
    },
    "id": "_LREB3dpscnH"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f5ab3b8b104dcdb6651b49c0459f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.83k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca46cfc37974c23a5012aed042a4712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.28k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset ag_news/default (download: 29.88 MiB, generated: 30.23 MiB, post-processed: Unknown size, total: 60.10 MiB) to /Users/antonermak/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39da1db2342b442ca257736e4924875a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/11.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e07766999e5475db5bfaf900bb82ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/751k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ag_news downloaded and prepared to /Users/antonermak/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f21615f6754db5b48c71ac310ccb7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 120000\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"ag_news\")\n",
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-07T15:05:11.531767Z",
     "start_time": "2022-09-07T15:05:11.522349Z"
    },
    "id": "-YysP5HpsiBX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\",\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QK1tDYKaTJa"
   },
   "source": [
    "–í `dataset` –Ω–∞—Ö–æ–¥—è—Ç—Å—è `train` –∏ `test` —á–∞—Å—Ç–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-07T15:07:18.631978Z",
     "start_time": "2022-09-07T15:07:18.610122Z"
    },
    "id": "wjEB-Yv09AQo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 120000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmSIXBJPaegW"
   },
   "source": [
    "–ß—Ç–æ–±—ã –ø—Ä–µ–≤—Ä–∞—â–∞—Ç—å —Ç–µ–∫—Å—Ç –∏–∑ –Ω–∞–±–æ—Ä–∞ —Å–ª–æ–≤ –≤ –Ω–∞–±–æ—Ä –≤–µ–∫—Ç–æ—Ä–æ–≤ –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏. –ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –∏—Ö —Å–ø–∏—Å–æ–∫ –∏ –≤—ã–±–µ—Ä–µ–º –æ–¥–∏–Ω –∏–∑ –Ω–∏—Ö."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-07T15:07:19.550971Z",
     "start_time": "2022-09-07T15:07:19.341966Z"
    },
    "id": "FGW4jSiswVDy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasttext-wiki-news-subwords-300\n",
      "conceptnet-numberbatch-17-06-300\n",
      "word2vec-ruscorpora-300\n",
      "word2vec-google-news-300\n",
      "glove-wiki-gigaword-50\n",
      "glove-wiki-gigaword-100\n",
      "glove-wiki-gigaword-200\n",
      "glove-wiki-gigaword-300\n",
      "glove-twitter-25\n",
      "glove-twitter-50\n",
      "glove-twitter-100\n",
      "glove-twitter-200\n",
      "__testing_word2vec-matrix-synopsis\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(api.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-07T15:10:47.091888Z",
     "start_time": "2022-09-07T15:07:20.082926Z"
    },
    "id": "xd1RzPKhwC3q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[================================================--] 97.1% 193.8/199.5MB downloaded\n"
     ]
    }
   ],
   "source": [
    "word2vec = api.load(\"glove-twitter-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAIznT0Kaue8"
   },
   "source": [
    "–¢–æ–∫–µ–Ω–µ–∑–∏—Ä—É–µ–º –Ω–∞—à —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-07T15:11:23.560622Z",
     "start_time": "2022-09-07T15:10:47.108007Z"
    },
    "id": "F6k91UgcAQNz"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc1bc8dda424513bc105a64d598be08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93eab1d6eb3a49a0a015897d51766be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7600 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH=128\n",
    "\n",
    "tokenizer = nltk.WordPunctTokenizer()\n",
    "\n",
    "dataset = dataset.map(\n",
    "    lambda item: {\n",
    "        \"tokenized\": tokenizer.tokenize(item[\"text\"])[:MAX_LENGTH]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqrtz1bDk2Ws"
   },
   "source": [
    "–°–æ–∑–¥–∞–¥–∏–º –º–∞–ø–∏–Ω–≥ –∏–∑ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-07T15:11:24.733940Z",
     "start_time": "2022-09-07T15:11:23.565174Z"
    },
    "id": "SMDWoNeEArA6"
   },
   "outputs": [],
   "source": [
    "word2idx = {word: idx for idx, word in enumerate(word2vec.index2word)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4G_q_EgHlCWC"
   },
   "source": [
    "–ü–µ—Ä–µ–≤–µ–¥–µ–º —Ç–æ–∫–µ–Ω—ã –≤ –∏–Ω–¥–µ–∫—Å—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-07T15:11:24.754861Z",
     "start_time": "2022-09-07T15:11:24.746175Z"
    },
    "id": "WVQX-b8mEKtA"
   },
   "outputs": [],
   "source": [
    "def encode(word):\n",
    "    if word in word2idx.keys():\n",
    "        return word2idx[word]\n",
    "    return word2idx[\"unk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-07T15:12:14.488049Z",
     "start_time": "2022-09-07T15:11:24.759177Z"
    },
    "id": "r9byefh6DSjV"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aaa0e5dfdb742acb7c9349214761d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8d78c97aba47dab01ba376bb1d79bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7600 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(\n",
    "    lambda item: {\n",
    "        \"features\": [encode(word) for word in item[\"tokenized\"]]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-07T15:12:14.543379Z",
     "start_time": "2022-09-07T15:12:14.500767Z"
    },
    "id": "Y05UCYA4D0OC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\",\n",
       " 'label': 2,\n",
       " 'tokenized': ['Wall',\n",
       "  'St',\n",
       "  '.',\n",
       "  'Bears',\n",
       "  'Claw',\n",
       "  'Back',\n",
       "  'Into',\n",
       "  'the',\n",
       "  'Black',\n",
       "  '(',\n",
       "  'Reuters',\n",
       "  ')',\n",
       "  'Reuters',\n",
       "  '-',\n",
       "  'Short',\n",
       "  '-',\n",
       "  'sellers',\n",
       "  ',',\n",
       "  'Wall',\n",
       "  'Street',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'dwindling',\n",
       "  '\\\\',\n",
       "  'band',\n",
       "  'of',\n",
       "  'ultra',\n",
       "  '-',\n",
       "  'cynics',\n",
       "  ',',\n",
       "  'are',\n",
       "  'seeing',\n",
       "  'green',\n",
       "  'again',\n",
       "  '.'],\n",
       " 'features': [62980,\n",
       "  62980,\n",
       "  1,\n",
       "  62980,\n",
       "  62980,\n",
       "  62980,\n",
       "  62980,\n",
       "  13,\n",
       "  62980,\n",
       "  17,\n",
       "  62980,\n",
       "  20,\n",
       "  62980,\n",
       "  28,\n",
       "  62980,\n",
       "  28,\n",
       "  49286,\n",
       "  4,\n",
       "  62980,\n",
       "  62980,\n",
       "  48,\n",
       "  137,\n",
       "  214902,\n",
       "  370,\n",
       "  1645,\n",
       "  39,\n",
       "  8606,\n",
       "  28,\n",
       "  380053,\n",
       "  4,\n",
       "  70,\n",
       "  1321,\n",
       "  1745,\n",
       "  389,\n",
       "  1]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-07T15:15:14.225761Z",
     "start_time": "2022-09-07T15:15:13.787153Z"
    },
    "id": "UiHvDSTAHJ8D"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'features'],\n",
       "        num_rows: 120000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'features'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.remove_columns([\"text\", \"tokenized\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOI1-AlYlbgA"
   },
   "source": [
    "–ü–µ—Ä–µ–≤–µ–¥–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-07T15:15:16.910101Z",
     "start_time": "2022-09-07T15:15:16.882040Z"
    },
    "id": "6VZ9EBnCK9V3"
   },
   "outputs": [],
   "source": [
    "dataset.set_format(type='torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-07T15:15:38.853717Z",
     "start_time": "2022-09-07T15:15:38.711430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'tokenized', 'features'],\n",
       "        num_rows: 120000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'tokenized', 'features'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-07T15:15:18.445630Z",
     "start_time": "2022-09-07T15:15:17.453349Z"
    },
    "id": "FWdVJKsnPtYX"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'numpy.str_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6q/6lhcsz8d367_fdnlq8mnrfg00000gn/T/ipykernel_55772/1325078361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: F811\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2164\u001b[0m         \u001b[0;34m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2165\u001b[0;31m         return self._getitem(\n\u001b[0m\u001b[1;32m   2166\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2167\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_getitem\u001b[0;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mformat_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0mpa_subtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m         formatted_output = format_table(\n\u001b[0m\u001b[1;32m   2151\u001b[0m             \u001b[0mpa_subtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_all_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_all_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0mpython_formatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPythonFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat_columns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRowFormat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumnFormat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchFormat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"row\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/datasets/formatting/torch_formatter.py\u001b[0m in \u001b[0;36mformat_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_arrow_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"torch.Tensor\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/datasets/formatting/torch_formatter.py\u001b[0m in \u001b[0;36mrecursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmap_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recursive_tensorize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mnum_proc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mnum_proc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         mapped = [\n\u001b[0m\u001b[1;32m    394\u001b[0m             \u001b[0m_single_map_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mnum_proc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         mapped = [\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0m_single_map_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         ]\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;31m# Singleton first to spare some computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;31m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/datasets/formatting/torch_formatter.py\u001b[0m in \u001b[0;36m_recursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pytorch tensors cannot be instantied from an array of objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstruct\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubstruct\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/datasets/formatting/torch_formatter.py\u001b[0m in \u001b[0;36m_tensorize\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mdefault_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_tensor_kwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'numpy.str_'"
     ]
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6haisMrlmSu"
   },
   "source": [
    "–•–æ—Ç–∏–º —Å–∫–ª–µ–∏—Ç—å –æ–±—ä–µ–∫—Ç—ã —Ä–∞–∑–Ω–æ–π –¥–ª–∏–Ω–Ω—ã –≤ –±–∞—Ç—á–∏. –î–ª—è —ç—Ç–æ–≥–æ –¥–∞–≤–∞–π—Ç–µ –Ω–∞–ø–∏—à–µ–º `collate_fn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-07T15:15:18.758633Z",
     "start_time": "2022-09-07T15:15:18.711937Z"
    },
    "id": "hzwuahwBxb2l"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    max_len = max(len(row[\"features\"]) for row in batch)\n",
    "    input_embeds = torch.empty((len(batch), max_len), dtype=torch.long)\n",
    "    labels = torch.empty(len(batch), dtype=torch.long)\n",
    "    for idx, row in enumerate(batch):\n",
    "        to_pad = max_len - len(row[\"features\"])\n",
    "        input_embeds[idx] = torch.cat((row[\"features\"], torch.zeros(to_pad)))\n",
    "        labels[idx] = row[\"label\"]\n",
    "    return {\"features\": input_embeds, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-07T15:12:15.662331Z",
     "start_time": "2022-09-07T15:12:15.661710Z"
    },
    "id": "FdVbtWJzszbu"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    k: DataLoader(\n",
    "        ds, shuffle=(k==\"train\"), batch_size=32, collate_fn=collate_fn\n",
    "    ) for k, ds in dataset.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbsqpZ-WfPqe"
   },
   "source": [
    "## CNN\n",
    "\n",
    "–ü–µ—Ä–≤–∞—è –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä—É—é –º—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º: CNN. –û–¥–Ω–æ–º–µ—Ä–Ω–∞—è –∫–æ–Ω–≤–æ–ª—é—Ü–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ö–æ—Ä–æ—à–æ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å –∑–∞–¥–∞—á–µ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏. –í –∫–æ–Ω—Ü–µ –Ω–∞–¥–æ —Å–æ–±—Ä–∞—Ç—å –≤–µ–∫—Ç–æ—Ä —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é `AdaptiveMaxPool1d` –∏–ª–∏ `AdiptiveAvgPool1d`. –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ—Ñ–∏–∫–∞—Ü–∏–∏ –º–æ–∂–Ω–æ —Å–æ–±—Ä–∞—Ç—å –ª—é–±—É—é Feed Forward Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9DMopWCiBlD"
   },
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(len(word2idx), embedding_dim=embed_size)\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(embed_size, hidden_size, kernel_size=3, padding=1, stride=2),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden_size, hidden_size, kernel_size=3, padding=1, stride=2),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden_size, hidden_size, kernel_size=3, padding=1, stride=2),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveMaxPool1d(1),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.cl = nn.Sequential(\n",
    "            nn.Linear(hidden_size, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)  # (batch_size, seq_len, embed_dim)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.cnn(x)\n",
    "        prediction = self.cl(x)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Ed-3nQHjDrd"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = CNNModel(word2vec.vector_size, 50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9oZjYEBkgauj"
   },
   "source": [
    "–ü–æ–¥–≥–æ—Ç–æ–≤–∏–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y7Smd5_03CSp"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "\n",
    "def training(model, criterion, optimizer, num_epochs, loaders, max_grad_norm=2):\n",
    "    for e in trange(num_epochs, leave=False):\n",
    "        model.train()\n",
    "        num_iter = 0\n",
    "        pbar = tqdm(loaders[\"train\"], leave=False)\n",
    "        for batch in pbar:\n",
    "            optimizer.zero_grad()\n",
    "            input_embeds = batch[\"features\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            prediction = model(input_embeds)\n",
    "            loss = criterion(prediction, labels)\n",
    "            loss.backward()\n",
    "            if max_grad_norm is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "            num_iter += 1\n",
    "        valid_loss = 0\n",
    "        valid_acc = 0\n",
    "        num_iter = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            num_objs = 0\n",
    "            for batch in loaders[\"test\"]:\n",
    "                input_embeds = batch[\"features\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "                prediction = model(input_embeds)\n",
    "                valid_loss += criterion(prediction, labels)\n",
    "                correct += (labels == prediction.argmax(-1)).float().sum()\n",
    "                num_objs += len(labels)\n",
    "                num_iter += 1\n",
    "\n",
    "        print(f\"Valid Loss: {valid_loss / num_iter}, accuracy: {correct/num_objs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oOi77V2XjDpg"
   },
   "outputs": [],
   "source": [
    "training(model, criterion, optimizer, num_epochs, loaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FN8E8-ZSgnul"
   },
   "source": [
    "## RNN\n",
    "\n",
    "–í—Ç–æ—Ä–∞—è –º–æ–¥–µ–ª—å: RNN. –≠—Ç–æ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–∞—è —Å–µ—Ç—å, –æ–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏–∑ –ø—Ä–æ—à–ª–æ–π –∏—Ç—Ç–µ—Ä–∞—Ü–∏–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–≥–æ. –≠—Ç–æ –æ–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è —Å –ø–æ–º–æ—â—å—é —Ñ–æ—Ä–º—É–ª:\n",
    "\n",
    "$$\n",
    "h_t = \\tanh(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh})\n",
    "$$\n",
    "\n",
    "–ù–∞–ø–∏—à–µ–º —ç—Ç–æ—Ç –º–æ–¥—É–ª—å –Ω–∞ `Torch`!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zBKQXeMOwie-"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.w_h = nn.Parameter(torch.rand(hidden_size, hidden_size))\n",
    "        self.b_h = nn.Parameter(torch.rand((1, hidden_size)))\n",
    "        self.w_x = nn.Parameter(torch.rand(embed_size, hidden_size))\n",
    "        self.b_x = nn.Parameter(torch.rand(1, hidden_size))\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        '''\n",
    "        x ‚Äì torch.FloatTensor with the shape (bs, seq_length, emb_size)\n",
    "        hidden - torch.FloatTensro with the shape (bs, hidden_size)\n",
    "        return: torch.FloatTensor with the shape (bs, hidden_size)\n",
    "        '''\n",
    "        if hidden is None:\n",
    "            hidden = torch.zeros((x.size(0), self.hidden_size)).to(x.device)\n",
    "        seq_length = x.size(1)\n",
    "        for cur_idx in range(seq_length):\n",
    "            hidden = torch.tanh(\n",
    "                x[:, cur_idx] @ self.w_x + self.b_x + hidden @ self.w_h + self.b_h\n",
    "            )\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LJ3ZIuZzamP"
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(len(word2idx), embed_size)\n",
    "        self.rnn = RNN(embed_size, hidden_size)\n",
    "        self.cls = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        hidden = self.rnn(x)\n",
    "        output = self.cls(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ftuDhqdtzaj-"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = RNNModel(word2vec.vector_size, 50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "num_epochs = 1\n",
    "max_grad_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yx62ofTU3CNY"
   },
   "outputs": [],
   "source": [
    "training(model, criterion, optimizer, num_epochs, loaders, max_grad_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XJqh9eWIhxE0"
   },
   "source": [
    "## GRU\n",
    "\n",
    "–¢—Ä–µ—Ç—å—è –º–æ–¥–µ–ª—å: GRU. –û–Ω–∞ —É—Å–ª–æ–∂–Ω–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è `RNN`. –ì–ª–∞–Ω–∞—è –∏–¥–µ—è GRU: –≥–µ–π—Ç—ã. –¢–∞–∫ —Ä–µ–∞–ª–∏–∑—É–µ—Ç—Å—è \"–ø–∞–º—è—Ç—å\" –º–æ–¥–µ–ª–∏ ‚Äì –æ–Ω–∞ –º–∞—Å–∫–∏—Ä—É–µ—Ç —á–∞—Å—Ç—å —Å—Ç–∞—Ä–æ–≥–æ —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è, —Å–æ–∑–¥–∞–≤–∞—è –Ω–∞ —ç—Ç–æ–º –º–µ—Å—Ç–µ –Ω–æ–≤–æ–µ. –ú–æ–¥–µ–ª—å GRU –æ–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "            r_t = \\sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\\\\n",
    "            z_t = \\sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\\\\n",
    "            n_t = \\tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn})) \\\\\n",
    "            h_t = (1 - z_t) * n_t + z_t * h_{(t-1)}\n",
    "        \\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hi1yv2cy3CJB"
   },
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.w_rh = nn.Parameter(torch.rand(hidden_size, hidden_size))\n",
    "        self.b_rh = nn.Parameter(torch.rand((1, hidden_size)))\n",
    "        self.w_rx = nn.Parameter(torch.rand(embed_size, hidden_size))\n",
    "        self.b_rx = nn.Parameter(torch.rand(1, hidden_size))\n",
    "\n",
    "        self.w_zh = nn.Parameter(torch.rand(hidden_size, hidden_size))\n",
    "        self.b_zh = nn.Parameter(torch.rand((1, hidden_size)))\n",
    "        self.w_zx = nn.Parameter(torch.rand(embed_size, hidden_size))\n",
    "        self.b_zx = nn.Parameter(torch.rand(1, hidden_size))\n",
    "\n",
    "        self.w_nh = nn.Parameter(torch.rand(hidden_size, hidden_size))\n",
    "        self.b_nh = nn.Parameter(torch.rand((1, hidden_size)))\n",
    "        self.w_nx = nn.Parameter(torch.rand(embed_size, hidden_size))\n",
    "        self.b_nx = nn.Parameter(torch.rand(1, hidden_size))\n",
    "\n",
    "    def forward(self, x, hidden = None):\n",
    "        '''\n",
    "        x ‚Äì torch.FloatTensor with the shape (bs, seq_length, emb_size)\n",
    "        hidden - torch.FloatTensro with the shape (bs, hidden_size)\n",
    "        return: torch.FloatTensor with the shape (bs, hidden_size)\n",
    "        '''\n",
    "        if hidden is None:\n",
    "            hidden = torch.zeros((x.size(0), self.hidden_size)).to(x.device)\n",
    "        \n",
    "        for cur_idx in range(x.size(1)):\n",
    "            r = torch.sigmoid(\n",
    "                x[:, cur_idx] @ self.w_rx + self.b_rx + hidden @ self.w_rh + self.b_rh\n",
    "            )\n",
    "            z = torch.sigmoid(\n",
    "                x[:, cur_idx] @ self.w_zx + self.b_zx + hidden @ self.w_zh + self.b_zh\n",
    "            )\n",
    "            n = torch.tanh(\n",
    "                x[:, cur_idx] @ self.w_nx + self.b_nx + r * (hidden @ self.w_nh + self.b_nh)\n",
    "            )\n",
    "            hidden = (1 - z) * n + z * hidden\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bisyVic-3CDu"
   },
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(len(word2idx), embed_size)\n",
    "        self.gru = GRU(embed_size, hidden_size)\n",
    "        self.cls = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        hidden = self.gru(x)\n",
    "        output = self.cls(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UASjrUtDzaf3"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = GRUModel(word2vec.vector_size, 50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "num_epochs = 1\n",
    "max_grad_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wlom9sHdzac6"
   },
   "outputs": [],
   "source": [
    "training(model, criterion, optimizer, num_epochs, loaders, max_grad_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mG4My7G5i5Vs"
   },
   "source": [
    "## GRU + Embeddings\n",
    "\n",
    "–ú—ã –Ω–µ –ø—Ä–æ—Å—Ç–æ —Ç–∞–∫ –∑–∞–≥—Ä—É–∑–∏–ª–∏ —ç–º–±—ç–¥–∏–Ω–≥–∏ –≤ –Ω–∞—á–∞–ª–µ. –î–∞–≤–∞–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏—Ö –≤–º–µ—Å—Ç–æ —Å–ª—É—á–∞–π–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏! –î–ª—è —ç—Ç–æ–≥–æ –Ω–∞–¥–æ –Ω–µ–º–Ω–æ–≥–æ –ø–µ—Ä–µ–¥–µ–ª–∞—Ç—å —Å–ø–æ—Å–æ–± –ø–æ–¥–∞—á–∏ –¥–∞–Ω–Ω—ã—Ö –≤ –º–æ–¥–µ–ª—å –∏ –¥–æ–±–∞–≤–∏—Ç—å –≤ –º–æ–¥–µ–ª—å –º–æ–¥—É–ª—å `Embedding`. –ü–æ-—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É–µ–º –Ω–∞ –º–æ–¥–µ–ª–∏ `GRU`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SbYLzLdYLxjc"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = GRUModel(word2vec.vector_size, 50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "num_epochs = 1\n",
    "max_grad_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-TxEwzMLsuz"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for word, idx in word2idx.items():\n",
    "        if word in word2vec:\n",
    "            model.embed.weight[idx] = torch.from_numpy(word2vec.get_vector(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Opw85y82Mhvf"
   },
   "outputs": [],
   "source": [
    "training(model, criterion, optimizer, num_epochs, loaders, max_grad_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T91mZsx_b8z8"
   },
   "source": [
    "–ü–æ–ø—Ä–æ–±—É–µ–º –∑–∞–º–æ—Ä–æ–∑–∏—Ç—å —ç–º–±–µ–¥–∏–Ω–≥–∏ –Ω–∞ –ø–µ—Ä–≤—ã—Ö –∏—Ç–µ—Ä–∞—Ü–∏—è—Ö –æ–±—É—á–µ–Ω–∏—è. –≠—Ç–æ –ø–æ–º–æ–∂–µ—Ç –Ω–µ —Å–∏–ª—å–Ω–æ –ø–æ—Ä—Ç–∏—Ç—å –Ω–∞—à–∏ —ç–º–±–µ–¥–∏–Ω–≥–∏ –Ω–∞ –ø–µ—Ä–≤—ã—Ö –∏—Ç–µ—Ä–∞—Ü–∏—è—Ö."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trrbDTJqMvLK"
   },
   "outputs": [],
   "source": [
    "def freeze_embeddings(model, req_grad=False):\n",
    "    embeddings = model.embed\n",
    "    for c_p in embeddings.parameters():\n",
    "        c_p.requires_grad = req_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zcPZxlseJME5"
   },
   "outputs": [],
   "source": [
    "def training_freeze(model, criterion, optimizer, num_epochs, loaders, max_grad_norm=2, num_freeze_iter=1000):\n",
    "    freeze_embeddings(model)\n",
    "    for e in trange(num_epochs, leave=False):\n",
    "        model.train()\n",
    "        num_iter = 0\n",
    "        pbar = tqdm(loaders[\"train\"], leave=False)\n",
    "        for batch in pbar:\n",
    "            if num_iter > num_freeze_iter and e < 1:\n",
    "                freeze_embeddings(model, True)\n",
    "            optimizer.zero_grad()\n",
    "            input_embeds = batch[\"features\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            prediction = model(input_embeds)\n",
    "            loss = criterion(prediction, labels)\n",
    "            loss.backward()\n",
    "            if max_grad_norm is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "            num_iter += 1\n",
    "        valid_loss = 0\n",
    "        valid_acc = 0\n",
    "        num_iter = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            num_objs = 0\n",
    "            for batch in loaders[\"test\"]:\n",
    "                input_embeds = batch[\"features\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "                prediction = model(input_embeds)\n",
    "                valid_loss += criterion(prediction, labels)\n",
    "                correct += (labels == prediction.argmax(-1)).float().sum()\n",
    "                num_objs += len(labels)\n",
    "                num_iter += 1\n",
    "\n",
    "        print(f\"Valid Loss: {valid_loss / num_iter}, accuracy: {correct/num_objs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fYbcqM2iKERh"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = GRUModel(word2vec.vector_size, 50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "num_epochs = 1\n",
    "max_grad_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E3i8-_MhKHCo"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for word, idx in word2idx.items():\n",
    "        if word in word2vec:\n",
    "            model.embed.weight[idx] = torch.from_numpy(word2vec.get_vector(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jKIdxoobKLas"
   },
   "outputs": [],
   "source": [
    "training_freeze(model, criterion, optimizer, num_epochs, loaders, max_grad_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_JDRH3TkK6VS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "seminar_cnn and rnn",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
